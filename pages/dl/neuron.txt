======= 神经元：Neuron=======
神经网络''(neural network)''的最基本单位，以最经典的''sigmoid''函数作为激活函数，那么一个神经元对于一个输入向量$A = (a_1, a_2, a_3, ..., a_n)$的操作为见下图： \\ \\ 
{{ :dl:neuron.png |神经元}} \\ 

可以看到上图中神经元其实是由两部分组成：第一部分是加权和，第二部分则是激活函数的非线性变换；\\ 
对于单个神经元，要学习的参数包括权值和偏置，即$w_1, w_2, w_3, ..., w_n, b$; \\ 
激活函数的输入为第一部分的加权和，常用的激活函数有:
  * ''sigmoid'': $$f(x)=\frac{1}{1 + exp(-x)}$$
  * ''tanh'': $$f(x)=\frac{exp(x) - exp(-x)}{exp(x) + exp(-x)}$$
  * ''ReLU'': $$f(x)=max\{0, x\} $$
前两者是光滑的曲线，''sigmoid''将输入映射到''(0, 1)''，而''tanh''将输入映射到''(-1, 1)''； \\ 
后者''ReLU''则是取''0''和输入的较大值；